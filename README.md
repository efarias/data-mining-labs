# üè• Lab Integrador U3 - Medical Diagnosis Classification

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.x-green.svg)](https://scikit-learn.org/)
[![MLflow](https://img.shields.io/badge/MLflow-2.x-blue.svg)](https://mlflow.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-success.svg)]()

> Laboratorio Integrador Profesional de Miner√≠a de Datos enfocado en clasificaci√≥n m√©dica con stack completo de MLOps.

---

## üìã Tabla de Contenidos

- [Descripci√≥n](#-descripci√≥n)
- [Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
- [Stack Tecnol√≥gico](#-stack-tecnol√≥gico)
- [Objetivos de Aprendizaje](#-objetivos-de-aprendizaje)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Pipeline MLOps](#-pipeline-mlops)
- [Modelos Implementados](#-modelos-implementados)
- [Resultados](#-resultados)
- [Herramientas Profesionales](#-herramientas-profesionales)
- [Contribuci√≥n](#-contribuci√≥n)
- [Licencia](#-licencia)
- [Autor](#-autor)

---

## üéØ Descripci√≥n

Laboratorio integrador de nivel profesional que implementa un pipeline completo de Machine Learning para diagn√≥stico de enfermedades card√≠acas utilizando el dataset **UCI Heart Disease**. El proyecto cubre todo el ciclo de vida de ML: desde EDA exhaustivo hasta deployment-ready models con interpretabilidad completa.

### üèÜ Destacados

- ‚úÖ **5 modelos de ML** entrenados y comparados
- ‚úÖ **Stack MLOps completo** (MLflow, Optuna, SHAP, Evidently)
- ‚úÖ **Optimizaci√≥n autom√°tica** de hiperpar√°metros
- ‚úÖ **Interpretabilidad** con 6 tipos de visualizaciones SHAP
- ‚úÖ **Validaci√≥n exhaustiva** con Deepchecks (30+ checks)
- ‚úÖ **Reportes autom√°ticos** profesionales
- ‚úÖ **C√≥digo reproducible** con seeds y versionado

---

## ‚ú® Caracter√≠sticas Principales

### üìä An√°lisis Exploratorio de Datos (EDA)

- An√°lisis univariado y bivariado completo
- Detecci√≥n y an√°lisis de outliers
- Visualizaciones profesionales con Yellowbrick
- An√°lisis cl√≠nico espec√≠fico por grupos de edad
- Reducci√≥n dimensional (PCA, t-SNE, UMAP)

### ü§ñ Machine Learning Pipeline

- **Preprocesamiento robusto** sin data leakage
- **5 modelos implementados:**
  1. Logistic Regression (baseline)
  2. Random Forest (optimizado)
  3. XGBoost (optimizado)
  4. Neural Network (Deep Learning)
  5. Ensemble (Voting Classifier)
  
### üîß Optimizaci√≥n de Hiperpar√°metros

- **Optuna** para b√∫squeda autom√°tica (60 trials total)
- Visualizaci√≥n del proceso de optimizaci√≥n
- Logging autom√°tico en MLflow
- Estrategias adaptativas seg√∫n modelo

### üìà MLOps & Tracking

- **MLflow** para experiment tracking
- Registro autom√°tico de:
  - Par√°metros
  - M√©tricas
  - Modelos
  - Artifacts
- UI interactiva v√≠a ngrok

### üîç Interpretabilidad

- **SHAP Analysis** exhaustivo:
  - Summary plots (global importance)
  - Dependence plots (feature interactions)
  - Waterfall plots (individual predictions)
  - Force plots (multiple cases)
  - Decision plots (prediction trajectories)
- An√°lisis de coherencia cl√≠nica

### ‚úÖ Validaci√≥n & Monitoring

- **Deepchecks** full suite (30+ validaciones)
- **Evidently AI** para reportes de clasificaci√≥n
- An√°lisis de calibraci√≥n de probabilidades
- Cross-validation estratificada

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Core ML/DL

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-FE8C00?style=for-the-badge)

### MLOps & Tracking

![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)
![Optuna](https://img.shields.io/badge/Optuna-5B5B5B?style=for-the-badge)

### Visualizaci√≥n & An√°lisis

![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge)
![Seaborn](https://img.shields.io/badge/Seaborn-3776AB?style=for-the-badge)
![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=for-the-badge&logo=plotly&logoColor=white)

### Interpretabilidad & Validaci√≥n

| Herramienta | Prop√≥sito | Nivel de Uso |
|-------------|-----------|--------------|
| **SHAP** | Explicabilidad de modelos | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Yellowbrick** | Visualizaci√≥n de diagn√≥stico | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Evidently AI** | Reportes autom√°ticos | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Deepchecks** | Validaci√≥n de modelos | ‚≠ê‚≠ê‚≠ê‚≠ê |

### Desarrollo

![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)
![Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)

---

## üéì Objetivos de Aprendizaje

Al completar este laboratorio, los estudiantes ser√°n capaces de:

1. ‚úÖ Realizar an√°lisis exploratorio exhaustivo (EDA) de datos m√©dicos
2. ‚úÖ Implementar preprocesamiento profesional evitando data leakage
3. ‚úÖ Entrenar y optimizar m√∫ltiples modelos de ML (baseline ‚Üí avanzados)
4. ‚úÖ Usar **Optuna** para optimizaci√≥n autom√°tica de hiperpar√°metros
5. ‚úÖ Registrar experimentos con **MLflow** para reproducibilidad
6. ‚úÖ Generar visualizaciones profesionales con **Yellowbrick**
7. ‚úÖ Crear reportes autom√°ticos con **Evidently AI**
8. ‚úÖ Interpretar modelos usando **SHAP** (explicabilidad)
9. ‚úÖ Validar modelos con **Deepchecks** antes de deployment
10. ‚úÖ Seleccionar modelos usando m√©tricas compuestas apropiadas

---

## üìÅ Estructura del Proyecto

```
Lab_Integrador_U3/
‚îÇ
‚îú‚îÄ‚îÄ üìì Lab_Integrador_U3_Medical_Diagnosis.ipynb    # Notebook principal
‚îÇ
‚îú‚îÄ‚îÄ üìä outputs/                                      # Artefactos generados
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ shap_statistics.csv
‚îÇ   ‚îú‚îÄ‚îÄ evidently_classification_report.html
‚îÇ   ‚îú‚îÄ‚îÄ deepchecks_validation_report.html
‚îÇ   ‚îî‚îÄ‚îÄ *.png                                       # Visualizaciones
‚îÇ
‚îú‚îÄ‚îÄ üóÇÔ∏è mlruns/                                      # Experimentos MLflow
‚îÇ   ‚îú‚îÄ‚îÄ 0/                                          # Experiment ID
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ meta.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [run_ids]/
‚îÇ   ‚îî‚îÄ‚îÄ models/                                     # Modelos registrados
‚îÇ
‚îú‚îÄ‚îÄ üèÜ best_model_*.pkl                             # Mejor modelo guardado
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                                    # Este archivo
‚îú‚îÄ‚îÄ üìã CHANGELOG.md                                 # Historial de versiones
‚îú‚îÄ‚îÄ üìú LICENSE                                      # Licencia MIT
‚îî‚îÄ‚îÄ üìù requirements.txt                             # Dependencias
```

---

## üöÄ Instalaci√≥n

### Opci√≥n 1: Google Colab (Recomendado)

```python
# 1. Subir notebook a Google Colab
# 2. Ejecutar celda de instalaci√≥n (ya incluida):

!pip install -q optuna mlflow yellowbrick evidently shap deepchecks xgboost imbalanced-learn pyngrok
```

‚è±Ô∏è Tiempo de instalaci√≥n: 2-3 minutos

### Opci√≥n 2: Entorno Local

```bash
# 1. Clonar repositorio
git clone https://github.com/tuusuario/lab-integrador-u3.git
cd lab-integrador-u3

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate      # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Iniciar Jupyter
jupyter notebook Lab_Integrador_U3_Medical_Diagnosis.ipynb
```

### Requisitos del Sistema

- **Python**: 3.8 o superior
- **RAM**: 8GB m√≠nimo (16GB recomendado)
- **Espacio**: 2GB disponibles
- **GPU**: Opcional (acelera Neural Network)

---

## üíª Uso

### Ejecuci√≥n Completa

```python
# En Google Colab o Jupyter:

# 1. Ejecutar celda de instalaci√≥n
# 2. Ejecutar todas las celdas: Runtime > Run all
# 3. Esperar 15-25 minutos (depende del hardware)
# 4. Acceder a MLflow UI con el link ngrok generado
```

### Ejecuci√≥n por Fases

El notebook est√° dividido en 16 fases modulares:

1. **FASE 1-2**: Setup e imports
2. **FASE 3**: Configuraci√≥n MLflow + ngrok
3. **FASE 4**: Carga de datos
4. **FASE 5**: EDA exhaustivo (9 subfases)
5. **FASE 6**: Preprocesamiento
6. **FASE 7-11**: Entrenamiento de 5 modelos
7. **FASE 12**: Selecci√≥n del mejor modelo
8. **FASE 13**: SHAP Analysis
9. **FASE 14**: Validaci√≥n con Deepchecks
10. **FASE 15**: (Opcional) Evidently AI
11. **FASE 16**: Resumen ejecutivo

### Outputs Generados

Despu√©s de ejecutar el notebook completo:

```
outputs/
‚îú‚îÄ‚îÄ üìä model_comparison_final.png              # Comparaci√≥n visual
‚îú‚îÄ‚îÄ üìà shap_1_summary_beeswarm.png            # SHAP global
‚îú‚îÄ‚îÄ üìà shap_2_importance_bar.png              # Feature ranking
‚îú‚îÄ‚îÄ üìà shap_3_dependence_plots.png            # Interacciones
‚îú‚îÄ‚îÄ üìà shap_4_waterfall_plots.png             # Explicaciones individuales
‚îú‚îÄ‚îÄ üìà shap_5_force_plot.png                  # M√∫ltiples casos
‚îú‚îÄ‚îÄ üìà shap_6_decision_plot.png               # Trayectorias
‚îú‚îÄ‚îÄ üìä shap_statistics.csv                     # Estad√≠sticas SHAP
‚îú‚îÄ‚îÄ üìã model_comparison_results.csv            # Resultados finales
‚îú‚îÄ‚îÄ üìÑ evidently_classification_report.html    # Reporte Evidently
‚îú‚îÄ‚îÄ üìÑ deepchecks_validation_report.html       # Validaci√≥n completa
‚îî‚îÄ‚îÄ üìù resumen_ejecutivo.md                    # Resumen Markdown
```

---

## üîÑ Pipeline MLOps

### Workflow Completo

```mermaid
graph LR
    A[üìä Raw Data] --> B[üîç EDA]
    B --> C[‚öôÔ∏è Preprocessing]
    C --> D[ü§ñ Model Training]
    D --> E[üéØ HPO Optuna]
    E --> F[üìà MLflow Tracking]
    F --> G[üîç SHAP Analysis]
    G --> H[‚úÖ Deepchecks Validation]
    H --> I[üìä Evidently Reports]
    I --> J[üèÜ Best Model Selection]
    J --> K[üíæ Model Registry]
    K --> L[üöÄ Deployment Ready]
```

### Caracter√≠sticas MLOps

#### 1. **Experiment Tracking (MLflow)**

- ‚úÖ Tracking autom√°tico de experimentos
- ‚úÖ Registro de par√°metros, m√©tricas y artifacts
- ‚úÖ Versionado de modelos
- ‚úÖ UI interactiva para comparaci√≥n
- ‚úÖ Model registry integrado

#### 2. **Hyperparameter Optimization (Optuna)**

- ‚úÖ B√∫squeda autom√°tica de hiperpar√°metros
- ‚úÖ 60 trials total (20 por modelo optimizado)
- ‚úÖ Pruning autom√°tico de trials no prometedores
- ‚úÖ Visualizaci√≥n de optimization history
- ‚úÖ Integraci√≥n con MLflow

#### 3. **Model Interpretability (SHAP)**

- ‚úÖ 6 tipos de visualizaciones
- ‚úÖ An√°lisis global y local
- ‚úÖ Feature interactions
- ‚úÖ Validaci√≥n cl√≠nica de features
- ‚úÖ Exportable para stakeholders

#### 4. **Model Validation (Deepchecks)**

- ‚úÖ 30+ validaciones autom√°ticas
- ‚úÖ Data integrity checks
- ‚úÖ Train-test validation
- ‚úÖ Model performance checks
- ‚úÖ Reporte HTML interactivo

#### 5. **Monitoring (Evidently AI)**

- ‚úÖ Reportes de clasificaci√≥n
- ‚úÖ An√°lisis de performance
- ‚úÖ Detecci√≥n de drift
- ‚úÖ M√©tricas por clase
- ‚úÖ Visualizaciones interactivas

---

## ü§ñ Modelos Implementados

### 1. Logistic Regression (Baseline)

**Configuraci√≥n:**
```python
LogisticRegression(
    random_state=42,
    max_iter=1000,
    solver='lbfgs'
)
```

**Prop√≥sito:** Establecer baseline simple e interpretable.

**Resultados T√≠picos:**
- Accuracy: ~86-87%
- F1-Score: ~86-87%
- ROC-AUC: ~95%

---

### 2. Random Forest (Optimizado con Optuna)

**Espacio de B√∫squeda:**
```python
{
    'n_estimators': [50, 300],
    'max_depth': [3, 20],
    'min_samples_split': [2, 20],
    'min_samples_leaf': [1, 10]
}
```

**Trials:** 20  
**Tiempo:** ~3-5 minutos

**Resultados T√≠picos:**
- Accuracy: ~91-92%
- F1-Score: ~91-92%
- ROC-AUC: ~96-97%

---

### 3. XGBoost (Optimizado con Optuna)

**Espacio de B√∫squeda:**
```python
{
    'n_estimators': [50, 300],
    'max_depth': [3, 8],
    'learning_rate': [0.01, 0.3],
    'subsample': [0.6, 1.0],
    'colsample_bytree': [0.6, 1.0],
    'gamma': [0, 0.5],
    'reg_alpha': [0, 1.0],
    'reg_lambda': [0, 1.0]
}
```

**Trials:** 20  
**Tiempo:** ~3-5 minutos

**Resultados T√≠picos:**
- Accuracy: ~90-91%
- F1-Score: ~90%
- ROC-AUC: ~95%

---

### 4. Neural Network (Deep Learning)

**Arquitectura:**
```python
Sequential([
    Dense(24, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(16, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(8, activation='relu'),
    Dropout(0.15),
    Dense(1, activation='sigmoid')
])
```

**Training:**
- Optimizer: Adam
- Loss: Binary Crossentropy
- Early Stopping: patience=15
- Learning Rate Reduction

**Resultados T√≠picos:**
- Accuracy: ~88-89%
- F1-Score: ~87-88%
- ROC-AUC: ~90-91%

---

### 5. Ensemble (Voting Classifier)

**Configuraci√≥n:**
```python
VotingClassifier(
    estimators=[
        ('lr', logistic_regression),
        ('rf', random_forest),
        ('xgb', xgboost)
    ],
    voting='soft'  # Promedia probabilidades
)
```

**Resultados T√≠picos:**
- Accuracy: ~90-91%
- F1-Score: ~89-90%
- ROC-AUC: ~96%

---

## üìä Resultados

### Comparaci√≥n de Modelos (Ejemplo)

| Modelo | Train Acc | Test Acc | F1-Score | ROC-AUC | Train-Test Gap |
|--------|-----------|----------|----------|---------|----------------|
| Logistic Regression | 0.851 | 0.869 | 0.867 | 0.951 | -0.018 |
| **Random Forest** | **0.860** | **0.918** | **0.912** | **0.965** | **-0.058** |
| XGBoost | 0.988 | 0.902 | 0.900 | 0.950 | 0.086 |
| Neural Network | 0.847 | 0.885 | 0.877 | 0.905 | -0.038 |
| Ensemble | 0.913 | 0.902 | 0.897 | 0.962 | 0.012 |

### Selecci√≥n del Mejor Modelo

**Criterio: Composite Score**
```
Score = 0.4 √ó AUC + 0.4 √ó F1 + 0.2 √ó Accuracy
```

**Por qu√© esta f√≥rmula:**
- **AUC (40%):** Capacidad de discriminaci√≥n (cr√≠tico en medicina)
- **F1 (40%):** Balance precisi√≥n-recall (evita falsos negativos)
- **Accuracy (20%):** Desempe√±o general

**Penalizaci√≥n:** Si Train-Test Gap > 5%, se aplica penalizaci√≥n por overfitting.

### Top Features seg√∫n SHAP

T√≠picamente los 3 features m√°s importantes son:

1. **ca** (n√∫mero de vasos principales): Indicador directo de enfermedad
2. **cp** (tipo de dolor de pecho): S√≠ntoma primario
3. **thalach** (frecuencia card√≠aca m√°xima): Capacidad card√≠aca

---

## üî® Herramientas Profesionales

### MLflow

**Uso:**
```python
import mlflow

# Iniciar experimento
mlflow.set_experiment("medical_diagnosis")

# Logging autom√°tico
with mlflow.start_run():
    mlflow.log_params(params)
    mlflow.log_metrics(metrics)
    mlflow.sklearn.log_model(model, "model")
```

**Beneficios:**
- Tracking de experimentos
- Comparaci√≥n de runs
- Versionado de modelos
- UI interactiva

---

### Optuna

**Uso:**
```python
import optuna

def objective(trial):
    # Definir espacio de b√∫squeda
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300),
        'max_depth': trial.suggest_int('max_depth', 3, 20)
    }
    
    # Entrenar y evaluar
    model = RandomForestClassifier(**params)
    score = cross_val_score(model, X, y, cv=5).mean()
    return score

# Optimizar
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=20)
```

**Beneficios:**
- Optimizaci√≥n autom√°tica
- Pruning inteligente
- Visualizaci√≥n del proceso
- Integraci√≥n con MLflow

---

### SHAP

**Uso:**
```python
import shap

# Crear explainer
explainer = shap.TreeExplainer(model)

# Calcular SHAP values
shap_values = explainer.shap_values(X_test)

# Visualizar
shap.summary_plot(shap_values, X_test)
shap.waterfall_plot(shap_values[0])
```

**Beneficios:**
- Explicabilidad completa
- An√°lisis global y local
- Feature interactions
- Visualizaciones profesionales

---

### Yellowbrick

**Uso:**
```python
from yellowbrick.classifier import ClassificationReport, ROCAUC

# Classification report
visualizer = ClassificationReport(model)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.show()

# ROC-AUC curves
visualizer = ROCAUC(model)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.show()
```

**Beneficios:**
- Visualizaciones instant√°neas
- Diagn√≥stico r√°pido
- Profesional out-of-the-box

---

### Evidently AI

**Uso:**
```python
from evidently.report import Report
from evidently.metric_preset import ClassificationPreset

# Crear reporte
report = Report(metrics=[ClassificationPreset()])
report.run(reference_data=train_df, current_data=test_df)
report.save_html('classification_report.html')
```

**Beneficios:**
- Reportes autom√°ticos
- An√°lisis exhaustivo
- Detecci√≥n de drift
- HTML interactivo

---

### Deepchecks

**Uso:**
```python
from deepchecks.tabular.suites import full_suite
from deepchecks.tabular import Dataset

# Crear datasets
train_ds = Dataset(X_train, label=y_train, cat_features=categorical)
test_ds = Dataset(X_test, label=y_test, cat_features=categorical)

# Ejecutar suite
suite = full_suite()
result = suite.run(train_dataset=train_ds, test_dataset=test_ds, model=model)
result.save_as_html('validation_report.html')
```

**Beneficios:**
- 30+ validaciones
- Data integrity
- Model performance
- Reporte profesional

---

## ü§ù Contribuci√≥n

¬°Las contribuciones son bienvenidas!

### C√≥mo Contribuir

1. Fork el proyecto
2. Crea tu feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### √Åreas de Mejora

- [ ] Agregar m√°s modelos (LightGBM, CatBoost)
- [ ] Implementar cross-validation estratificada
- [ ] Agregar an√°lisis de calibraci√≥n
- [ ] Desarrollar API REST con FastAPI
- [ ] Containerizaci√≥n con Docker
- [ ] CI/CD con GitHub Actions
- [ ] Deployment en cloud (AWS/GCP/Azure)

---

## üìú Licencia

Este proyecto est√° bajo la Licencia MIT. Ver archivo [LICENSE](LICENSE) para m√°s detalles.

```
MIT License

Copyright (c) 2025 Eduardo Far√≠as Reyes

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## üë®‚Äçüè´ Autor

**Eduardo Far√≠as Reyes**  
Profesor de Miner√≠a de Datos  
Instituto Profesional Santo Tom√°s - Arica, Chile

**Contacto:**
- üìß Email: [efarias4@santotomas.cl]
- üíº LinkedIn: [[efarias](https://www.linkedin.com/in/efariasr/)]
- üêô GitHub: [@efarias](https://github.com/efarias)

---

## üéì Contexto Acad√©mico

**Curso:** Miner√≠a de Datos (IEI-097)  
**Instituci√≥n:** Instituto Profesional Santo Tom√°s  
**Nivel:** 6¬∫ Semestre - Ingenier√≠a en Inform√°tica  
**A√±o:** 2025

### Objetivos del Curso

Este laboratorio integrador forma parte del curso de Miner√≠a de Datos y busca:

1. ‚úÖ Aplicar t√©cnicas avanzadas de ML en problemas reales
2. ‚úÖ Familiarizar estudiantes con herramientas profesionales
3. ‚úÖ Desarrollar habilidades en MLOps
4. ‚úÖ Fomentar buenas pr√°cticas de desarrollo
5. ‚úÖ Preparar para roles en la industria

---

## üôè Agradecimientos

- **UCI Machine Learning Repository** por el dataset Heart Disease
- **Anthropic** por Claude (asistencia en desarrollo)
- **Comunidad Open Source** por las incre√≠bles herramientas
- **Estudiantes de IEI-097** por feedback continuo

---

## üìö Referencias

1. **Dataset:** [UCI Heart Disease](https://archive.ics.uci.edu/ml/datasets/heart+disease)
2. **MLflow:** [https://mlflow.org/docs/latest/](https://mlflow.org/docs/latest/)
3. **Optuna:** [https://optuna.readthedocs.io/](https://optuna.readthedocs.io/)
4. **SHAP:** [https://shap.readthedocs.io/](https://shap.readthedocs.io/)
5. **Evidently:** [https://docs.evidentlyai.com/](https://docs.evidentlyai.com/)
6. **Deepchecks:** [https://docs.deepchecks.com/](https://docs.deepchecks.com/)

---

## üèÜ Logros

- ‚úÖ **5 modelos** entrenados y comparados
- ‚úÖ **60 trials** de optimizaci√≥n Optuna
- ‚úÖ **6 visualizaciones** SHAP generadas
- ‚úÖ **30+ validaciones** Deepchecks ejecutadas
- ‚úÖ **100% reproducible** con seeds y MLflow
- ‚úÖ **Nivel industria** en herramientas y pr√°cticas

---

<div align="center">

### ‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub ‚≠ê

**Desarrollado con ‚ù§Ô∏è para la comunidad de Data Science**

</div>

---

**√öltima actualizaci√≥n:** 17 de Noviembre de 2025  
**Versi√≥n:** 3.4.0
